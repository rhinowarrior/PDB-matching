"""
Name: calculate_rmsd.py
Function: Calculate LRMSD, IRMSD, and FNAT between reference and decoy files.
Date: 16-10-2024
Author: Jan Aarts, Farzaneh Meimandi Parizi, Nils Smit
"""

from Bio.PDB import PDBParser
from pathlib import Path
import os
from sys import argv
from pdb2sql.StructureSimilarity import StructureSimilarity

def add_suffix(path, suffix):
    """Adds a suffix to the filename and returns the new Path object.
    
    Args:
        path (Path): Path object to the file
        suffix (str): Suffix to be added to the filename
    
    Returns:
        Path: Path object with the new filename
    """
    before = path.parent
    after = path.stem
    return Path(before, f"{after}_{suffix}{path.suffix}")   

def parse_clustering_file(clustering_path):
    """Parses a clustering file and extracts model names.
    
    Args:
        clustering_path (str): Path to the clustering file
    
    Returns:
        list: List of model names
    """
    models = []
    with open(clustering_path, 'r') as f:
        lines = f.readlines()
    for line in lines:
        # Extract the model name from the line
        if line.startswith("Cluster center: "):
            model_name = line.split("Cluster center: ")[-1]
            model_name = model_name.split("with")[0].strip()
            cleaned_name = model_name.replace("merged_", "").replace(".pdb", "").strip()
            models.append(cleaned_name)
    return models

def search_for_clustering_files(base_dir, cluster_input):
    """Search for clustering files and create a dictionary of models.
    
    Args:
        base_dir (str): Path to the directory containing the clustering files
        cluster_input (str): Name of the clustering file
    
    Returns:
        dict: Dictionary containing the model identifiers and their clustering
    """
    model_dict = {}
    base_path = Path(base_dir)
    
    for model_dir in base_path.glob('**/'):
        cluster_file_path = model_dir / cluster_input
        if cluster_file_path.exists():
            key = model_dir.stem[:4]
            models = parse_clustering_file(cluster_file_path)
            model_dict[key] = models
    
    return model_dict

def calc_LRMSD_decoys(ref_file, decoy_files):
    """Calculates LRMSD, IRMSD, and FNAT between reference and decoy files.
    
    Args:
        ref_file (str): Path to the reference PDB file
        decoy_files (list): List of paths to the decoy PDB files
    
    Returns:
        tuple: Tuple containing lists of LRMSD, IRMSD, and FNAT values
    """
    lrmsds, irmsds, fnats = [], [], []

    PDBParser().get_structure('pdb_ref', ref_file)

    for decoy_file in decoy_files:
        try:
            PDBParser().get_structure('pdb_decoy', decoy_file)
            sim = StructureSimilarity(ref_file, decoy_file, enforce_residue_matching=False)

            # ref.Lzone file is automaticlly generated by the pdb2sql package. it is created by aligning the longest chain of the decoy to the one of the reference and computing the RMSD of the shortest chain between decoy and reference.
            lrmsd_pdb2sql = sim.compute_lrmsd_fast(lzone='ref.lzone')
            irmsd_pdb2sql = sim.compute_irmsd_fast()
            fnat_pdb2sql = sim.compute_fnat_fast()

            lrmsds.append(lrmsd_pdb2sql)
            irmsds.append(irmsd_pdb2sql)
            fnats.append(fnat_pdb2sql)

            print(f"{os.path.basename(decoy_file)} - LRMSD: {lrmsd_pdb2sql}, IRMSD: {irmsd_pdb2sql}, FNAT: {fnat_pdb2sql}")

        except Exception as e:
            print(f"Error in {os.path.basename(decoy_file)}: {str(e)}")

    return lrmsds, irmsds, fnats

def main():
    mapped_dir = Path(argv[1])       # Directory containing the mapped files
    original_dir = Path(argv[2])     # Directory with original reference models
    cluster_input = argv[3]           # Name of the clustering file
    outfile_base = Path(argv[4])      # Convert to Path object

    results_lrmsd = {}  # Dictionary to store results for LRMSD
    results_irmsd = {}  # Dictionary to store results for IRMSD
    results_fnat = {}   # Dictionary to store results for FNAT
    
    model_dict = search_for_clustering_files(original_dir, cluster_input)
    
    for model_identifier, file_numbers in model_dict.items():
        for file_number in file_numbers:
            # Create paths to the reference and decoy files
            ref_file = mapped_dir / f"{model_identifier}_reference_{file_number}_mapped.pdb"
            decoy_file = mapped_dir / f"{model_identifier}_merged_{file_number}_mapped.pdb"

            if ref_file.exists() and decoy_file.exists():
                print(f"Calculating RMSD for {ref_file.name} and {decoy_file.name}")
                lrmsd_values, irmsd_values, fnat_values = calc_LRMSD_decoys(ref_file, [decoy_file])
                
                # Store results under the model identifier
                if model_identifier not in results_lrmsd:
                    results_lrmsd[model_identifier] = []
                # Append all LRMSD values
                results_lrmsd[model_identifier].extend(lrmsd_values)

                if model_identifier not in results_irmsd:
                    results_irmsd[model_identifier] = []
                # Append all IRMSD values
                results_irmsd[model_identifier].extend(irmsd_values)
                
                if model_identifier not in results_fnat:
                    results_fnat[model_identifier] = []
                # Append all FNAT values
                results_fnat[model_identifier].extend(fnat_values)
            else:
                print(f"Files do not exist: {ref_file} or {decoy_file}")

    # Write results to separate output files in the specified format
    lrmsd_outfile = add_suffix(outfile_base, "lrmsd")
    irmsd_outfile = add_suffix(outfile_base, "irmsd")
    fnat_outfile = add_suffix(outfile_base, "fnat")

    with open(lrmsd_outfile, 'w') as f_lrmsd, \
         open(irmsd_outfile, 'w') as f_irmsd, \
         open(fnat_outfile, 'w') as f_fnat:

        for model_id, lrmsd_values in results_lrmsd.items():
            f_lrmsd.write(f"{model_id}\t" + "\t".join(f"{val}" for val in lrmsd_values) + "\n")

        for model_id, irmsd_values in results_irmsd.items():
            f_irmsd.write(f"{model_id}\t" + "\t".join(f"{val}" for val in irmsd_values) + "\n")

        for model_id, fnat_values in results_fnat.items():
            f_fnat.write(f"{model_id}\t" + "\t".join(f"{val}" for val in fnat_values) + "\n")

    print("Results written to", lrmsd_outfile, irmsd_outfile, fnat_outfile)

if __name__ == "__main__":
    main()
